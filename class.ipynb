{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "class.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np "
      ],
      "metadata": {
        "id": "L7xYVeDkgG0h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "56nWJHwAeLki"
      },
      "outputs": [],
      "source": [
        "class myLogisticRegression:\n",
        "\n",
        "  def __init__(self,solver='bgd',eta=0.3,thershold=0.5,n_epochs=100,lampda=0,alpha=1,batch_size=20,t0=200, t1=1000):\n",
        "    self.solver=solver\n",
        "    self.eta=eta\n",
        "    self.n_epochs=n_epochs\n",
        "    self.lampda=lampda\n",
        "    self.alpha=alpha\n",
        "    self.batch_size=batch_size\n",
        "    self.t0=t0\n",
        "    self.t1=t1\n",
        "    self.trained=False\n",
        "    self.thershold=thershold\n",
        "    self.cost_lst=list()\n",
        "\n",
        "  def sigmoid(self,z):\n",
        "    return 1.0/(1 + np.exp(-z))\n",
        "  def loss(self,y, y_hat):\n",
        "    loss = -np.mean(y*(np.log(y_hat)) + (1-y)*np.log(1-y_hat))\n",
        "    return loss\n",
        "  def learning_schedule(self,t):\n",
        "    return self.t0 / (t + self.t1)\n",
        "\n",
        "  def preprocessing(self,X,y):\n",
        "    X = np.c_[np.ones((X.shape[0], 1)), X] \n",
        "    y = y.reshape(len(y), 1)\n",
        "    return X,y\n",
        "\n",
        "#optimization algorithms\n",
        "  def bgd(self,X,y):\n",
        "    for iteration in range(self.n_epochs):\n",
        "      gradients = 1/self.m * X.T.dot(self.sigmoid(X.dot(self.theta)) - y)\n",
        "      regularization = self.lampda/self.m *( (1-self.alpha) * self.theta+self.alpha * np.sign(self.theta))\n",
        "      self.theta = self.theta - self.eta * (gradients + regularization)\n",
        "      cost_value=self.loss(y, self.sigmoid(X.dot(self.theta)))\n",
        "      self.cost_lst.append(cost_value)\n",
        "\n",
        "  def mbgd(self,X,y):\n",
        "    for epoch in range(self.n_epochs):\n",
        "      shuffled_indices = np.random.permutation(self.m)\n",
        "      X_b_shuffled = X[shuffled_indices]\n",
        "      y_shuffled = y[shuffled_indices]\n",
        "      t=0 #for the learning_schedule\n",
        "      for i in range(0, self.m, self.batch_size):\n",
        "          t+= 1 \n",
        "          xi = X_b_shuffled[i:i+self.batch_size]\n",
        "          yi = y_shuffled[i:i+self.batch_size]\n",
        "          regularization = self.lampda/self.batch_size * ((1-self.alpha) * self.theta + self.alpha * np.sign(self.theta))\n",
        "          gradients = 1/self.batch_size * xi.T.dot(self.sigmoid(xi.dot(self.theta)) - yi)\n",
        "          self.eta = self.learning_schedule(t)\n",
        "          self.theta = self.theta - self.eta * (gradients+regularization)\n",
        "      cost_value=self.loss(y, self.sigmoid(X.dot(self.theta)))\n",
        "      self.cost_lst.append(cost_value)\n",
        "  def sgd(self,X,y):\n",
        "    for epoch in range(self.n_epochs):\n",
        "      for i in range(self.m):        \n",
        "          random_index = np.random.randint(self.m)\n",
        "          xi = X[random_index].reshape(1,3)\n",
        "          yi = y[random_index].reshape(1,1)\n",
        "          regularization = self.lampda * ((1-self.alpha) * self.theta+self.alpha * np.sign(self.theta))\n",
        "          gradients =  xi.T.dot(self.sigmoid(xi.dot(self.theta)) - yi) \n",
        "          self.eta = self.learning_schedule(epoch * self.m + i)\n",
        "          self.theta = self.theta - self.eta * (gradients +regularization)\n",
        "          \n",
        "      cost_value=self.loss(y, self.sigmoid(X.dot(self.theta)))\n",
        "      self.cost_lst.append(cost_value)\n",
        "#training\n",
        "  def fit(self,X,y):\n",
        "    self.theta=np.random.randn(len(X[0])+1, 1)\n",
        "    self.m=X.shape[0]\n",
        "    self.trained = True\n",
        "    X,y=self.preprocessing(X,y)\n",
        "    \n",
        "    if self.solver=='bgd':\n",
        "      self.bgd(X,y)\n",
        "    elif self.solver=='mbgd':\n",
        "      self.mbgd(X,y)\n",
        "    elif self.solver=='sgd':\n",
        "      self.sgd(X,y)\n",
        "    else:raise Exception(\"error wrong solver\")\n",
        "\n",
        "#prediction \n",
        "  def predict(self,X):\n",
        "      pred_class = []\n",
        "      if self.trained == True:\n",
        "        X,_=self.preprocessing(X,np.array([0,0,0]))\n",
        "        pred=self.sigmoid(X.dot(self.theta))\n",
        "        pred_class = [1 if i > self.thershold else 0 for i in pred]\n",
        "        return np.array(pred_class)\n",
        "      else:\n",
        "        raise Exception(\"This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")\n",
        "\n",
        "  def predict_proba(self,X):\n",
        "      if self.trained == True:\n",
        "        X,_=self.preprocessing(X,np.array([0,0,0]))\n",
        "        return self.sigmoid(X.dot(self.theta))\n",
        "      else:\n",
        "        raise Exception(\"This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")\n",
        "  def get_cost(self):\n",
        "    return np.array(self.cost_lst)   "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from fractions import Fraction as frac\n",
        "import sys\n",
        "\n",
        "np.random.seed(42)\n",
        "from sklearn.datasets import make_classification\n",
        "X, y = make_classification(n_features=2, n_redundant=0, \n",
        "                           n_informative=2, random_state=1, \n",
        "                           n_clusters_per_class=1)"
      ],
      "metadata": {
        "id": "rz0RfBfB2dw2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = myLogisticRegression(solver='mbgd')\n",
        "model.fit(X,y)"
      ],
      "metadata": {
        "id": "07n5L8PUy-e_"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre=model.predict(X)\n",
        "pre"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kVWppL632Q6",
        "outputId": "41ff2df8-a35e-4d32-e1d8-df6032325029"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
              "       1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
              "       0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n",
              "       1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.theta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgyXOrPC4chc",
        "outputId": "a3e48fa7-2345-4fd1-e3f8-127174b05fa9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.15348587],\n",
              "       [-4.61754429],\n",
              "       [ 0.21202298]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cost=model.get_cost()\n",
        "cost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkfoj3Ebw6av",
        "outputId": "2aca9273-26ca-4627-ae22-8cf6733e7b03"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.84781203, 0.56114622, 0.40308215, 0.31018392, 0.25101191,\n",
              "       0.21065124, 0.18147498, 0.1594107 , 0.14220285, 0.12842872,\n",
              "       0.11714584, 0.10774141, 0.09975382, 0.09292312, 0.0869965 ,\n",
              "       0.08180231, 0.07721667, 0.07313412, 0.06947825, 0.06618462,\n",
              "       0.06320477, 0.06049091, 0.05800946, 0.05573147, 0.05363346,\n",
              "       0.05169551, 0.04989795, 0.04822663, 0.046668  , 0.0452118 ,\n",
              "       0.04384753, 0.04256766, 0.04136408, 0.04022925, 0.03915763,\n",
              "       0.03814455, 0.03718517, 0.03627518, 0.03541053, 0.03458796,\n",
              "       0.03380397, 0.03305691, 0.03234374, 0.03166235, 0.03101044,\n",
              "       0.03038579, 0.02978711, 0.02921257, 0.0286608 , 0.0281307 ,\n",
              "       0.02762058, 0.02712941, 0.02665628, 0.02620021, 0.02576039,\n",
              "       0.02533567, 0.02492531, 0.02452864, 0.02414515, 0.02377403,\n",
              "       0.02341472, 0.02306663, 0.02272929, 0.02240207, 0.02208459,\n",
              "       0.0217763 , 0.02147689, 0.02118612, 0.02090351, 0.02062868,\n",
              "       0.02036137, 0.02010109, 0.01984784, 0.01960119, 0.01936087,\n",
              "       0.01912658, 0.01889826, 0.0186756 , 0.01845835, 0.01824626,\n",
              "       0.01803923, 0.01783715, 0.01763976, 0.01744689, 0.01725839,\n",
              "       0.01707406, 0.01689385, 0.01671755, 0.01654508, 0.01637635,\n",
              "       0.01621114, 0.01604939, 0.01589106, 0.01573597, 0.01558398,\n",
              "       0.01543508, 0.01528909, 0.015146  , 0.01500569, 0.01486803])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "P0X7SJ3txBPt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}